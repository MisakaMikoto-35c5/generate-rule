#!/usr/bin/python3

import json
import base64
import urllib.request, urllib.error

class IllegalRuleException(RuntimeError):
    pass

class ProxyRuleUpdater:

    USER_AGENT = 'ProxyRuleUpdater/0.2'
    FILE_HEADER_FORMAT = '# Generated by ProxyRuleUpdater/0.2\n\n'
    OUTPUT_PATH = '.'

    #CRLF = True

    def get_config_value(self, array, key, default_value):
        try:
            return array[key]
        except KeyError:
            return default_value

    def get_file_header(self):
        return self.FILE_HEADER_FORMAT

    def save_file(self, filename, content, file_header = None):
        if content == file_header:
            return
        f = open(filename, 'w+', encoding='utf-8')
        f.write(content)
        f.close()
    
    def __clear_uniq_cache(self):
        self.__uniq_cache = {}

    def __uniq(self, find_str):
        try:
            index_obj = self.__uniq_cache[find_str[0]]
        except KeyError:
            self.__uniq_cache[find_str[0]] = []
            index_obj = self.__uniq_cache[find_str[0]]
        for i in index_obj:
            if i == find_str:
                return False
        index_obj.append(find_str)
        return True

    def gen_rule(self, config_path):
        f = open(config_path)
        config_raw_content = f.read()
        f.close()
        file_header = self.get_file_header()
        config_array = json.loads(config_raw_content)
        unbound_target_dns = ''
        for i in config_array['dns_servers']:
            unbound_target_dns += '\tforward-addr: ' + i + '\n'
        rules_list = config_array['rules_list']
        for rules_url in rules_list:
            self.__clear_uniq_cache()
            rules_download_url = rules_url['url']
            rules_type = rules_url['type']
            if rules_type == 'hosts':
                # 解析 hosts 文件
                action_type = self.get_config_value(rules_url, 'action_type', 'HOST-SUFFIX') # 默认匹配方式
                action = self.get_config_value(rules_url, 'action', 'REJECT') # 默认操作
                file_prefix = self.get_config_value(rules_url, 'file_prefix', rules_url['name']) # 文件前缀

                print('Downloading: ' + rules_url['name'])
                results = self.download_hosts_rule(rules_download_url)
                print('Download finish: ' + rules_url['name'])

                hostnames = file_header
                unbound_dns = file_header
                for i in results:
                    if self.__uniq(i):
                        hostnames += action_type + ',' + i + ',' + action + '\n'
                        if action == 'REJECT':
                            unbound_dns += 'local-zone: "' + i + '" refuse\n'
                        else:
                            unbound_dns += 'forward-zone:\n\tname: "' + i + '."\n' + unbound_target_dns + '\n'
                self.save_file(self.OUTPUT_PATH + '/' + file_prefix + '-hostnames.conf', hostnames, file_header) # 保存文件
                self.save_file(self.OUTPUT_PATH + '/' + file_prefix + '-unbound_dns.conf', unbound_dns, file_header)
            elif rules_type == 'adblock' or rules_type == 'gfwlist':
                # 解析 AdBlock 规则和 GFWlist 规则
                default_action = self.get_config_value(rules_url, 'default_action', 'REJECT') # 默认操作
                unsupport_convert = self.get_config_value(rules_url, 'unsupport_convert', 'REGEX') # 不能完全支持规则时的匹配方式
                unsupport_action = self.get_config_value(rules_url, 'unsupport_action', 'REJECT') # 不能完全支持规则时的操作
                file_prefix = self.get_config_value(rules_url, 'file_prefix', rules_url['name']) # 文件前缀

                if unsupport_convert == 'REGEX' and unsupport_action != 'REJECT':
                    raise IllegalRuleException('由于软件限制，正则表达式无法使用除拒绝外的所有操作。')
                print('Downloading: ' + rules_url['name'])
                if rules_type == 'adblock':
                    results = self.download_adblock_rule(rules_download_url, default_action, unsupport_convert, unsupport_action)
                elif rules_type == 'gfwlist':
                    results = self.download_gfwlist_rule(rules_download_url, default_action, unsupport_convert, unsupport_action)
                print('Download finish: ' + rules_url['name'])

                hostnames = file_header
                unbound_dns = file_header
                regex_rejection = file_header
                for i in results:
                    if i['prefer'] == 'HOST-SUFFIX' or i['prefer'] == 'HOST-KEYWORD' or i['prefer'] == 'HOST':
                        if i['domain'] == '':
                            continue
                        if self.__uniq(i['domain']):
                            hostnames += i['prefer'] + ',' + i['domain'] + ',' + i['action'] + '\n'
                        if i['prefer'] != 'HOST-KEYWORD':
                            if i['action'] == 'REJECT':
                                unbound_dns += 'local-zone: "' + i['domain'] + '" refuse\n'
                            else:
                                unbound_dns += 'forward-zone:\n\tname: "' + i['domain'] + '."\n' + unbound_target_dns + '\n'
                    elif i['prefer'] == 'REGEX':
                        if i['action'] != 'REJECT':
                            continue
                        if i['regex'] == '':
                            continue
                        regex_rejection += i['regex'] + '\n'
                self.save_file(self.OUTPUT_PATH + '/' + file_prefix + '-hostnames.conf', hostnames, file_header)
                self.save_file(self.OUTPUT_PATH + '/' + file_prefix + '-unbound_dns.conf', unbound_dns, file_header)
                self.save_file(self.OUTPUT_PATH + '/' + file_prefix + '-rejection.conf', regex_rejection, file_header)

    def make_surfboard_rules(self, config_path):
        f = open(config_path)
        config_raw_content = f.read()
        f.close()
        file_header = self.get_file_header()
        try:
            config_array = json.loads(config_raw_content)['surfboard_output']
        except:
            return
        config_file = file_header
        self.__clear_uniq_cache()
        for i in config_array['parts']:
            if i['type'] == 'base':
                for rule_file in i['files']:
                    config_file += f"\n# Rule type: {i['type']}, Rule file: {rule_file}\n\n"
                    rf = open(rule_file, encoding='utf-8')
                    config_file += rf.read()
                    rf.close()
            elif i['type'] == 'hostnames':
                action_replace = None
                try:
                    action_replace = i['action_replace']
                except KeyError:
                    pass
                self.__clear_uniq_cache()
                minify = False
                try:
                    minify = i['minify']
                except KeyError:
                    pass
                for rule_file in i['files']:
                    config_file += f"\n# Rule type: {i['type']}, Rule file: {rule_file}\n\n"
                    if minify:
                        config_file += '# Minify enabled.\n'
                    rf = open(rule_file, encoding='utf-8')
                    rules = rf.read().split('\n')
                    rf.close()
                    for rule in rules:
                        if rule.startswith('#'):
                            continue
                        if rule.isspace():
                            continue
                        if len(rule) == 0:
                            continue
                        rule = rule.split(',')
                        if self.__uniq(rule[1]):
                            match_type = self.convert_action_name(rule[0])
                            action = rule[2]
                            if action_replace != None:
                                try:
                                    action = action_replace[action]
                                except KeyError:
                                    pass
                            config_file +=  f'{match_type},{rule[1]},{action}\n'
        self.__clear_uniq_cache()
        self.save_file(self.OUTPUT_PATH + '/' + config_array['output_name'], config_file, file_header)

    def download_hosts_rule(self, url):
        http_content = self.get_web_content(url)
        rules = self.decode_hosts_rule(http_content['content'])
        return rules

    def download_adblock_rule(self, rules_download_url, default_action, unsupport_convert, unsupport_action):
        http_content = self.get_web_content(rules_download_url)
        rules = self.decode_adblock_rule(http_content['content'], default_action, unsupport_convert, unsupport_action)
        return rules

    def download_gfwlist_rule(self, rules_download_url, default_action, unsupport_convert, unsupport_action):
        http_content = self.get_web_content(rules_download_url)
        rules = self.decode_adblock_rule(base64.b64decode(http_content['content']).decode('utf-8'), default_action, unsupport_convert, unsupport_action)
        return rules
    
    def decode_hosts_rule(self, rules_list):
        now_rule_string = ''
        rules = []
        ignore_this_line = False
        space = False
        ip_path = False
        for rule_char in rules_list:
            if rule_char == '\n':
                if now_rule_string != '':
                    rules.append(now_rule_string)
                    now_rule_string = ''
                ignore_this_line = False
                space = False
                ip_path = False
                now_rule_string = ''
                continue
            if ignore_this_line or rule_char == '\r':
                continue
            if rule_char == '#':
                ignore_this_line = True
                continue
            if ip_path == False and now_rule_string == '':
                if rule_char != ' ' and rule_char != '\t':
                    ip_path = True
                continue
            if ip_path == True and rule_char == ' ' or rule_char == '\t':
                if space == False:
                    space = True
                elif now_rule_string != '':
                    ignore_this_line = True
                continue
            if space:
                now_rule_string += rule_char
        if now_rule_string != '':
            rules.append(now_rule_string)
            now_rule_string = ''
        return rules

    def decode_adblock_rule(self, rules_list, default_action = 'REJECT', unsupport_convert = 'REGEX', unsupport_action = 'REJECT', exclude_action = 'IGNORE'):
        rules = []
        rules_raw = rules_list.split('\n')
        # scheme: ^(https?://)?
        # 域名及子域名: ([0-9a-zA-Z_\-\.]*\.)?
        # 标记分隔符 ^: (?![0-9a-zA-Z_\-\.\%]).
        if len(rules_raw) == 0:
            return rules
        for rule in rules_raw:
            if len(rule) < 2:
                continue
            if rule[-1] == '\r':
                rule = rule[0:-1]
            first_str = rule[0]
            if first_str == '[' and rule[-1] == ']': # 去掉 [Adblock Plus 1.1] 这一行
                continue
            if first_str == '!': # 去掉注释行
                continue
            prev_str = ''
            generated_domain = ''
            generated_regex = ''

            char_path = -1 # 当前处理字符的位置，0 开始计
            domain_end = False # 标记停止记录域名
            prefix_match = False # 标记规则需要匹配前缀
            suffix_match = False # 标记规则需要匹配后缀
            path_length = 0 # 标记除域名后面的目录的长度
            subdomain = False # 标记规则需要匹配子域名
            regex_only = False # 标记规则只能用正则
            skip_char = 0 # 标记跳过多少字
            unsupport_rule = False # 标记不支持的规则
            for now_char in rule:
                char_path += 1
                if skip_char > 0:
                    skip_char -= 1
                    continue
                if char_path == 0:
                    if now_char == '|': # 检查开头是否匹配
                        prefix_match = True
                        generated_regex = '^'
                        prev_str = now_char
                        domain_end = False
                        continue
                    elif now_char == '@': # 去掉排除项
                        unsupport_rule = True
                        break
                    elif now_char == '/': # 正则规则，直接跳过
                        if rule[-1] == '/':
                            regex_only = True
                            generated_regex = rule[1:-1]
                            break
                        else:
                            regex_suffix = rule.find('/$')
                            rule_length = len(rule) - 2
                            if regex_suffix != -1 and regex_suffix != rule_length:
                                regex_only = True
                                generated_regex = rule[1:regex_suffix]
                                break
                elif regex_only == False and char_path == 1 and now_char == '|' and prev_str == '|': # 检查是否匹配子域名
                    subdomain = True
                    generated_regex += '(https?://)?([0-9a-zA-Z_\\-\\.]*\\.)?'
                    prev_str = now_char
                    continue
                if now_char == '$':
                    rule_options = rule[rule.find('$'):] # 检查是否有高度可能导致访问网站出问题的附加选项
                    if 'domain=' in rule_options or 'csp=' in rule_options or 'popup' in rule_options or 'popunder' in rule_options:
                        unsupport_rule = True
                    break
                if now_char == '#': # 不支持元素过滤，直接忽略
                    unsupport_rule = True
                    break
                elif (now_char == ':' and (generated_domain == 'http' or generated_domain == 'https' or generated_domain == 'http*')) and rule[char_path + 1:char_path + 3] == '//':
                    # 如果出现冒号检查是否是 scheme，如果是重新提取域名
                    generated_domain = ''
                    skip_char = 2
                    prev_str = '/'
                    generated_regex += '://'
                    continue
                elif domain_end == False and now_char == '/': # 如果出现路径则停止记录域名
                    domain_end = True
                elif now_char == '*': # 如果出现 * 则转换成正则的形式
                    generated_regex += '.'
                elif now_char == '^': # 如果出现分隔符则用正则替代，并且停止记录域名
                    generated_regex += '(?![0-9a-zA-Z_\-\.\%]).'
                    domain_end = True
                    generated_regex += now_char
                    prev_str = now_char # 记录最后一个字是什么
                    continue
                elif now_char in '.?-+[]{},\\': # 如果出现正则的特殊字符则在签名加一个转义符
                    generated_regex += '\\'
                if domain_end:
                    path_length += 1 # 记录域名后面的路径有多长，方便后面判断是否必须用正则
                else:
                    if now_char == '.' and generated_domain == '':
                        generated_regex += now_char
                        prev_str = now_char # 记录最后一个字是什么
                        continue
                    generated_domain += now_char # 记录域名
                generated_regex += now_char
                prev_str = now_char # 记录最后一个字是什么
            if unsupport_rule == False:
                if generated_domain == 'localhost':
                    continue
                if prev_str == '^': # 如果最后是分隔符，根据 AdBlock 的规则，在最后的分隔符可以没有
                    generated_regex += '?'
                elif prev_str == '|':
                    if rule[char_path-1] == '^': # 如果最后要求匹配结尾并且上一个是分隔符，就在正则后面加这些
                        generated_regex = generated_regex[0:len(generated_regex)-1] + '?$'
                    else: # 如果上一个字不是分隔符就不加问号
                        generated_regex = generated_regex[0:len(generated_regex)-1] + '$'
                maybe_domain_only = True
                if first_str != '|':
                    maybe_domain_only = False
                last_str = rule[char_path]
                if last_str == '$':
                    char_path -= 1
                    last_str = rule[char_path]
                if (maybe_domain_only and (path_length == 0 or path_length == 1)):
                    # 判断是否只包含域名的字符串，然后判断一下 path 的长度
                    # 先决条件满足以后检查一下最后面是不是 / 或分隔符，如果是的话就分域名或者子域名
                    # 如果不是的话就改用域名关键字
                    if last_str == '/' or last_str == '^':
                        if subdomain:
                            prefer = 'HOST-SUFFIX'
                        else:
                            prefer = 'HOST'
                    else:
                        if unsupport_convert != 'REGEX':
                            prefer = unsupport_convert
                        else:
                            prefer = 'HOST-KEYWORD'
                else:
                    # 如果明显不是域名就改用正则
                    prefer = unsupport_convert
                action = ''
                if prefer == 'HOST' or prefer == 'HOST-SUFFIX' or prefer == 'HOST-KEYWORD': # 如果是域名就用默认操作
                    if self.check_str_is_domain(generated_domain) == False: # 如果规则不支持用域名的方式但是用户要求用域名的时候把规则偏好改回正则避免出问题
                        prefer = 'REGEX'
                        action = unsupport_action
                    else: # 如果域名没问题就用域名的规则
                        action = default_action
                else:
                    action = unsupport_action # 如果不是就用正则的
                rules.append({'domain': generated_domain, 'regex': generated_regex, 'prefer': prefer, 'action': action})
        return rules

    def check_str_is_domain(self, domain):
        have_dot = False
        for i in domain:
            if i == '.':
                have_dot = True
            if i not in 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890_-.':
                return False
        return have_dot

    def _test_adblock_rule(self):
        while True:
            user_input = input('AdBlock Plus 1.1 rule: ')
            if user_input == 'exit':
                break
            print(self.decode_adblock_rule(user_input))
            print('')

    def get_web_content(self, url, post_data = None, headers = None):
        if url.startswith('file://'):
            f = open(url[7:], 'r', encoding='utf-8')
            content = f.read()
            f.close()
            return {'content': content, 'code': 200, 'headers': {}}
        default_headers = {
            'User-Agent': self.USER_AGENT
        }
        if headers != None:
            default_headers.update(headers)
        request = urllib.request.Request(url, headers = default_headers)
        try:
            response = urllib.request.urlopen(request, data = post_data)
        except urllib.error.HTTPError as e:
            response = e
        content = response.read()
        headers = response.headers
        content_type = headers['Content-Type']
        if content_type != None and len(content_type) > 4 and content_type[0:4] == 'text':
            content = content.decode('utf-8')
        return {'content': content, 'code': response.code, 'headers': headers}

    def convert_action_name(self, action, application='surfboard'):
        actions = {
            'HOST': 'HOST',
            'HOST-SUFFIX': 'HOST-SUFFIX',
            'HOST-KEYWORD': 'HOST-KEYWORD'
        }
        if application == 'surfboard':
            actions = {
                'HOST': 'DOMAIN',
                'HOST-SUFFIX': 'DOMAIN-SUFFIX',
                'HOST-KEYWORD': 'DOMAIN-KEYWORD'
            }
        try:
            return actions[action]
        except KeyError:
            return None
        

if __name__ == '__main__':
    foo = ProxyRuleUpdater()
    foo.OUTPUT_PATH = './generated_rules'
    config_file = './config.json'
    foo.gen_rule(config_file)
    foo.make_surfboard_rules(config_file)
    #foo._test_adblock_rule()
